{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit3cdd97de52a24b9daf52c2ea50aadc7e",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will start by training a model for detection \n",
    "##### Import all the libraries and modules required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a neural network\n",
    "\n",
    "##### This convolution network consists of two pairs of Conv and MaxPool layers to extract features from the dataset. Which is then followed by a Flatten and Dropout layer to convert the data in 1D and ensure overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential([\n",
    "    Conv2D(100, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(100, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Augmentation/Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 1315 images belonging to 2 classes.\nFound 194 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "TRAINING_DIR = './dataset/train/'\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    " rotation_range=40,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "   shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "     fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "batch_size=10,\n",
    "target_size=(150, 150))\n",
    "\n",
    "VALIDATION_DIR = './dataset/test'\n",
    "validation_datagen  = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    " batch_size=10,\n",
    " target_size=(150, 150))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a checkpoint to store best perfoming models & train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n132/132 [==============================] - ETA: 0s - loss: 0.5436 - acc: 0.7627WARNING:tensorflow:From /home/rebel/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: model2-001.model/assets\n132/132 [==============================] - 204s 2s/step - loss: 0.5436 - acc: 0.7627 - val_loss: 0.1525 - val_acc: 0.9433\nEpoch 2/10\n132/132 [==============================] - ETA: 0s - loss: 0.3172 - acc: 0.8760INFO:tensorflow:Assets written to: model2-002.model/assets\n132/132 [==============================] - 190s 1s/step - loss: 0.3172 - acc: 0.8760 - val_loss: 0.1199 - val_acc: 0.9691\nEpoch 3/10\n132/132 [==============================] - ETA: 0s - loss: 0.3015 - acc: 0.8882INFO:tensorflow:Assets written to: model2-003.model/assets\n132/132 [==============================] - 163s 1s/step - loss: 0.3015 - acc: 0.8882 - val_loss: 0.0588 - val_acc: 0.9845\nEpoch 4/10\n132/132 [==============================] - 169s 1s/step - loss: 0.2529 - acc: 0.9133 - val_loss: 0.1289 - val_acc: 0.9536\nEpoch 5/10\n132/132 [==============================] - 151s 1s/step - loss: 0.2511 - acc: 0.9049 - val_loss: 0.1407 - val_acc: 0.9227\nEpoch 6/10\n132/132 [==============================] - 162s 1s/step - loss: 0.1949 - acc: 0.9247 - val_loss: 0.1226 - val_acc: 0.9536\nEpoch 7/10\n132/132 [==============================] - 180s 1s/step - loss: 0.1992 - acc: 0.9186 - val_loss: 0.0633 - val_acc: 0.9691\nEpoch 8/10\n132/132 [==============================] - 186s 1s/step - loss: 0.1839 - acc: 0.9376 - val_loss: 0.2016 - val_acc: 0.8866\nEpoch 9/10\n132/132 [==============================] - ETA: 0s - loss: 0.1817 - acc: 0.9369INFO:tensorflow:Assets written to: model2-009.model/assets\n132/132 [==============================] - 206s 2s/step - loss: 0.1817 - acc: 0.9369 - val_loss: 0.0431 - val_acc: 0.9948\nEpoch 10/10\n132/132 [==============================] - 204s 2s/step - loss: 0.1958 - acc: 0.9293 - val_loss: 0.1287 - val_acc: 0.9330\n"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model2-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=10,\n",
    "validation_data=validation_generator,\n",
    "callbacks=[checkpoint])\n"
   ]
  }
 ]
}